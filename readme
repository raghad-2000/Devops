
# Project Title

A brief description of what this project does and who it's for


# DevOps - TP1

## Database 

### Basics
#### 1-1 Document your database container essentials: commands and Dockerfile.

Dockerfile : 
```
FROM postgres:14.1-alpine

ENV POSTGRES_DB=db \
   POSTGRES_USER=usr \
   POSTGRES_PASSWORD=pwd
```
build : 

```
$ docker build -t raghad/tp1 .
```
create network:

```
$ docker network create app-network

```
restart adminer :
```
$ docker run \
    -p "8090:8080" \
    --net=app-network \
    --name=adminer \
    -d \
    adminer
```
run docker image:
```
sudo docker run -p 8888:5000 --net=app-network --name tp1 raghad/tp1
```

**Why should we run the container with a flag -e to give the environment variables?**

-e is how you pass environment variables to the container to avoid putting sensitive data in Dockerfiles. 

so we remove POSTGRES_PASSWORD=pwd from Dockerfile and the new run commande will be :
```
sudo docker run -p 8888:5000 -d -e POSTGRES_PASSWORD=pwd --net=app-network --name tp1 raghad/tp1
```
---

### Database Init 

Create files CreateScheme.sql and InsertData.sql

Dockerfile : 
```
FROM postgres:14.1-alpine

ENV POSTGRES_DB=db \
   POSTGRES_USER=usr 

# INIT db
COPY CreateScheme.sql /usr/src/app/
COPY InsertData.sql /usr/src/app/

```

**Why do we need a volume to be attached to our postgres container?**

To persist data durably on the host disk in case the database container get destroyed

now we have :
```
& docker run -p 8888:5000 -d -e POSTGRES_PASSWORD=pwd --net=app-network -v /my/own/datadir:/var/lib/postgresql/data --name tp1 raghad/tp1
```

## Backend API

### Basics

create the Main.java

add the code in it :
```
public class Main {

   public static void main(String[] args) {
       System.out.println("Hello World!");
   }
}
```

Compile with your target Java: javac Main.java

Write dockerfile : 
```
FROM openjdk:11
COPY . /usr/src/myapp
WORKDIR /usr/src/myapp
RUN javac Main.java
CMD ["java", "Main"]
```

build : 
```
docker build -t raghad/java .
```
run :
```
docker run raghad/java
```
Hello World displayed :)

### Multistage build

Create and generate Springboot application on: Spring Initializer

create GreetingController.java at 
```
src
â”œâ”€â”€ main
â”‚Â Â  â”œâ”€â”€ java
â”‚Â Â  â”‚Â Â  â””â”€â”€ fr
â”‚Â Â  â”‚Â Â      â””â”€â”€ takima
â”‚Â Â  â”‚Â Â          â””â”€â”€ training
â”‚Â Â  â”‚Â Â              â””â”€â”€ simpleapi
â”‚Â Â  â”‚Â Â                  â”œâ”€â”€ controller
                            â””â”€â”€ GreetingController.java
```
build : 
```
docker build -t raghad/java .
```
run : 
```
docker run -d --net=app-network -p 8080:8080 java raghad/java
sudo docker run --name my-running-app --net=app-network -p 8081:80 raghad/my-apache2
```



**1-2 Why do we need a multistage build? And explain each step of this dockerfile.**

To contain the build in only one Dockerfile, it wont be necessary to have a seperate build script.

```
# Build
FROM maven:3.8.6-amazoncorretto-17 AS myapp-build    
ENV MYAPP_HOME /opt/myapp   
WORKDIR $MYAPP_HOME   
COPY pom.xml .   
COPY src ./src   
RUN mvn package -DskipTests   

# Run
FROM amazoncorretto:17     
ENV MYAPP_HOME /opt/myapp    
WORKDIR $MYAPP_HOME   
COPY --from=myapp-build $MYAPP_HOME/target/*.jar $MYAPP_HOME/myapp.jar

ENTRYPOINT java -jar myapp.jar
```

yml :
```
spring:
  jpa:
    properties:
      hibernate:
        jdbc:
          lob:
            non_contextual_creation: true
    generate-ddl: false
    open-in-view: true
  datasource:
    url: jdbc:postgresql://tp1:5432/db
    username: usr
    password: pwd
    driver-class-name: org.postgresql.Driver
management:
 server:
   add-application-context-header: false
 endpoints:
   web:
     exposure:
       include: health,info,env,metrics,beans,configprops

```

build : 
```
docker build -t raghad/java .
```
run :
```
doker run -p 8080:8080 -d --net=app-network --name java2 java2
```
now we can access our application API on: /departments/IRC/students.


---

## Http server
### Basics

Dockerfile : 
```
FROM httpd:2.4

COPY ./html/ /usr/local/apache2/htdocs/
```
build : 
```
sudo docker build -t raghad/apache2 .
```
run : 
```
sudo docker run -dit --name my-running-app -p 8081:81 raghad/apache2
```

### Reverse proxy 





# TP2

## First steps into the CI World

git Init

git add . 

git remote add master <project_url_with_https>

git push master


2-1 What are testcontainers?

They simply are java libraries that allow you to run a bunch of docker containers while testing. 

Devops/.github/workflows/main.yml

2-2 Document your Github Actions configurations.

```
name: CI devops 2023
on:
  #to begin you want to launch this job in main and develop
  push:
    branches: master 

jobs:
  test-backend: 
    runs-on: ubuntu-22.04
    steps:
     #checkout your github code using actions/checkout@v2.5.0
      - uses: actions/checkout@v2.5.0

     #do the same with another action (actions/setup-java@v3) that enable to setup jdk 17
      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
          java-version: '17'
          distribution: 'adopt'

     #finally build your app with the latest command
      - name: Build and test with Maven
        working-directory: java/simple-api-student-main/
        run: mvn verify
```
set up when we want to test the back end :  
- push

what branch :  
- master

set up JDK 17 

precise where the mvn verify will be executed :
- working directory 

## First steps into the CD World

we add build-and-push-docker-image job to the main.yml 
specify that it needs the test-back-end to be done before it executes 

in build image and push backend we specify the path where the Dockerfile is (context) and the dockerHub repository that it is published to (tags)
finaly (push) that publish the images 

we add in github, directory, settings, secrets and variables the enviroment variables we use in the main.yml to login to dockerhub

```
build-and-push-docker-image:
    needs: test-backend
    # run only when code is compiling and tests are passing
    runs-on: ubuntu-22.04

    # steps to perform in job
    steps:
      - name: Checkout code
        uses: actions/checkout@v2.5.0

      - name: Login to DockerHub
        run: docker login -u ${{ secrets.DOCKERHUB_USERNAME }} -p ${{ secrets.DOCKERHUB_TOKEN }}
     
      - name: Build image and push backend
        uses: docker/build-push-action@v3
        with:
          # relative path to the place where source code with Dockerfile is located
          context: ./java/simple-api-student-main/
          # Note: tags has to be all lower-case
          tags:  ${{secrets.DOCKERHUB_USERNAME}}/tp-devops-simple-api:latest
          push: ${{ github.ref == 'refs/heads/master' }}
      
```

We do the same (Build image and push backend) for database and httpd 

Now we have our working CI & docker images pushed to the dockerhub repository
---
Why did we put needs: build-and-test-backend on this job? 

Because we need the application to be compiled before building our docker image.
---
For what purpose do we need to push docker images?

By pushing Docker images, they become retrievable from any Docker, which can prove very useful for easy and rapid deployment.
---















### Setup Quality Gate

**Sonar** : Code monitoring platform for analysis purposes.

After configuring Sonar by linking it to the GitHub repository, we add the analysis to our file `main.yml` : 

```yml
      - name: Build and test with Maven
        working-directory: simple-api-student/
        run: mvn -B verify sonar:sonar -Dsonar.projectKey=Thomas0507_devOps-TP01 -Dsonar.organization=thomas0507 -Dsonar.host.url=https://sonarcloud.io -Dsonar.login=${{ secrets.SONAR_TOKEN }}
```

We had to add the Sonar tokens to our GitHub secrets.


Document your quality gate configuration.

We are using the sonar way, the default quality gate. The code passes the quality test if:

    There are no new bugs.
    There are no new vulnerabilities.
    New code has limited technical debt.
    All new security hotspots are covered.
    Sufficient tests cover the new code (> 80%).
    There is minimal duplication in the new code (< 3%)."


## TP 03 - Ansible ðŸ›¸ðŸ›¸ðŸ›¸

We install Ansible and create an inventory file at the root:

```
mkdir ansible
cd ansible
mkdir inventories
cd inventories
touch setup.yml
```

setup.yml:
```
 all:
 vars:
   ansible_user: centos
   ansible_ssh_private_key_file: ../../id_rsa
 children:
   prod:
     hosts: raghad.al-homsi.takima.cloud
```

ping:

```
sudo ansible all -i setup.yml -m ping
```

Response:
```
thomas.marin.takima.cloud | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": false,
    "ping": "pong"
}
```
Verify conf:

```
ansible all -i setup.yml -m setup -a  "filter=ansible_distribution*"
```
RÃ©ponse:
```
thomas.marin.takima.cloud | SUCCESS => {
    "ansible_facts": {
        "ansible_distribution": "CentOS",
        "ansible_distribution_file_parsed": true,
        "ansible_distribution_file_path": "/etc/redhat-release",
        "ansible_distribution_file_variety": "RedHat",
        "ansible_distribution_major_version": "7",
        "ansible_distribution_release": "Core",
        "ansible_distribution_version": "7.9",
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": false
}
```

If httpd is installed on the Ansible server, we uninstall it:

```
ansible all -i ansible/inventories/setup.yml -m yum -a "name=httpd state=absent" --become
```
Document your inventory and base commands

Inventaire:
- We provide the SSH key path and the username as variables.
- We also provide the address of our server

### Playbooks

Create playbook.yml:

```
touch ansible/playbook.yml
```

Ping:

```
ansible-playbook -i inventories/setup.yml playbook.yml
```


### Advanced Playbooks

```
- hosts: all
  gather_facts: false
  become: true

# Install Docker
  tasks:

  - name: Install device-mapper-persistent-data
    yum:
      name: device-mapper-persistent-data
      state: latest

  - name: Install lvm2
    yum:
      name: lvm2
      state: latest

  - name: add repo docker
    command:
      cmd: sudo yum-config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo

  - name: Install Docker
    yum:
      name: docker-ce
      state: present

  - name: Install python3
    yum:
      name: python3
      state: present

  - name: Install docker with Python 3
    pip:
      name: docker
      executable: pip3
    vars:
      ansible_python_interpreter: /usr/bin/python3

  - name: Make sure Docker is running
    service: name=docker state=started
    tags: docker
```

### Using Roles 

Create rÃ´le:

```
ansible-galaxy init roles/<ROLE_NAME>
```

Roles :
- app
- database
- docker
- network
- proxy

Each subdirectory of the 'roles' directory represents a role, and we can execute them from the playbook.yml.

Execute the roles from the playbook.yml file:

```
  roles:
    - app
    - database
    - docker
    - network
    - proxy
```


playbook.yml with the roles :


```yml
# Install Docker
- hosts: all
  gather_facts: false
  become: true
  vars_files:
    - group_vars/var.yml
  roles:
    - docker # install docker
    - network # crÃ©er un rÃ©seau pour les containers
    - database # lance la db
    - app # lance le backend
    - proxy # lance le reverse proxy
```


Document your playbook

We call each role to execute the tasks it contains.

### Deploy your App

After creating the specified roles, each one should execute a task. Their order is important, so we need to be careful. In continuation of our GitHub secrets, we need to add environment variables for the URLs, container names, network, and tokens.

So we create `group_vars\var.yml` :

```
#db
POSTGRES_CONTAINER: tp1
POSTGRES_DB: db
POSTGRES_USER: usr
POSTGRES_PASSWORD: pwd

# docker network
DOCKER_NETWORK: app-network

#backend
API_CONTAINER: springboot-app-container
```
Then encrypt with `ansible-vault`:

```bash
ansible-vault encrypt group_vars/var.yml
```

We are asked to enter a password that will be prompted during deployment.

Decrypte:

```yml
ansible-vault decrypt ansible/group_vars/var.yml
```

The different tasks executed by the roles:

- docker :

```yml
- name: Install device-mapper-persistent-data
  yum:
    name: device-mapper-persistent-data
    state: latest

- name: Install lvm2
  yum:
    name: lvm2
    state: latest

- name: add repo docker
  command:
    cmd: sudo yum-config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo

- name: Install Docker
  yum:
    name: docker-ce
    state: present

- name: Install python3
  yum:
    name: python3
    state: present

- name: Install docker with Python 3
  pip:
    name: docker
    executable: pip3
  vars:
    ansible_python_interpreter: /usr/bin/python3

- name: Make sure Docker is running
  service: name=docker state=started
  tags: docker
```
- network :
```yml
- name: Create docker network
  community.docker.docker_network:
    name: "{{ DOCKER_NETWORK }}" 
  vars:
    ansible_python_interpreter: /usr/bin/python3
```
- database :
```yml
- name: Run database
  vars:
    ansible_python_interpreter: /usr/bin/python3
  docker_container:
    name: "{{ POSTGRES_CONTAINER }}"
    image: raghad2000/tp-devops-db:latest
    networks:
      - name: "{{ DOCKER_NETWORK }}"
    env:
      POSTGRES_DB: "{{ POSTGRES_DB }}"
      POSTGRES_USER: "{{ POSTGRES_USER }}"
      POSTGRES_PASSWORD: "{{ POSTGRES_PASSWORD }}"
    volumes:
      - myvolume:/var/lib/postgresql/data
    recreate:
      true
    pull:
      true
```
- app :
```yml
- name: Run Backend API
  vars:
    ansible_python_interpreter: /usr/bin/python3
  docker_container:
    name: "{{ API_CONTAINER }}" 
    image: raghad2000/tp-devops-simple-api:latest
    networks:
      - name: "{{ DOCKER_NETWORK }}" 
    env:
      URL: "{{ POSTGRES_CONTAINER }}:5432" 
      POSTGRES_DB: "{{ POSTGRES_DB }}" 
      POSTGRES_USER: "{{ POSTGRES_USER }}" 
      POSTGRES_PASSWORD: "{{ POSTGRES_PASSWORD }}"
    recreate: true
    pull: true
```
- proxy :
```yml
- name: Run HTTPD
  vars:
    ansible_python_interpreter: /usr/bin/python3
  docker_container:
    name: httpd
    image: raghad2000/tp-devops-httpd:latest
    networks:
      - name: "{{ DOCKER_NETWORK }}" 
    ports:
      - 8080:80
    # env:
    #   API_URL: "{{ API_CONTAINER }}"
    recreate: true
    pull: true
```



Document your docker_container tasks configuration. ðŸ‡ºðŸ‡¸

- docker: We install all dependencies and Docker using yum.
- network: We create a Docker network with the name specified in the var.yml file and specifying the Python version.
- database: We specify the Python version. We retrieve the Docker image of our database from Docker Hub and specify its network. We pass the superuser login credentials as environment variables. We specify the location of its volume to maintain data persistence. We ensure that the image is always rebuilt and pulled from the Docker repository.
- app: Similar to the above, we retrieve the Docker image from Docker Hub and instantiate it with its environment variables.
- Similarly, but here we also specify its exposed port.

Since we have encrypted our var.yml, it is essential to enter the password of the vault during deployment:

```bash
sudo ansible-playbook --ask-vault-pass -i ansible/inventories/setup.yml ansible/playbook.yml
```


## Author

- [@Raghad AL HOMSI](https://github.com/raghad-2000/Devops/tree/master)

